# 项目目录（给 AI 代理直接照此创建）

<pre class="overflow-visible!" data-start="135" data-end="1561"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>tcmrx/
├─ </span><span>README</span><span>.md
├─ pyproject.toml
├─ .gitignore
│─ TCM-MKG-data/           </span><span># 原始tsv文件目录，包含多个数据说明MD文件</span><span>
├─ config/
│  ├─ default.yaml          </span><span># 超参数与开关（均可为空或关闭）</span><span>
│  └─ paths.yaml            </span><span># 所有 TSV 的路径（绝对/相对均可）</span><span>
│
├─ dataio/                  </span><span># 只做：读TSV → 连接 → 过滤 → 组装样本（全在内存）</span><span>
│  ├─ __init__.py
│  ├─ schema_map.py        </span><span># 各TSV的列名常量与注释（唯一依据：列名说明.md）</span><span>
│  ├─ readers.py           </span><span># pandas 读TSV + 轻校验（必需列/空表）</span><span>
│  ├─ joins.py             </span><span># 业务连接：疾病靶点集、方剂靶点集</span><span>
│  ├─ filters.py           </span><span># 可选过滤/加权（TopK、pKi阈值、剂量softmax、逆频）</span><span>
│  ├─ id_maps.py           </span><span># 稳定的 string_id↔int 索引映射</span><span>
│  └─ dataset_builder.py   </span><span># 组装 (Disease, Formula) 训练/验证样本</span><span>
│
├─ core/
│  ├─ __init__.py
│  ├─ batching.py          </span><span># PyTorch Dataset/DataLoader（仅用内存对象）</span><span>
│  ├─ losses.py            </span><span># InfoNCE（对称 in-batch negatives）</span><span>
│  ├─ metrics.py           </span><span># Recall@K</span><span>/NDCG</span><span>@K</span><span>
│  └─ utils.py             </span><span># 日志、随机种、断言</span><span>
│
├─ models/
│  ├─ __init__.py
│  ├─ encoders.py          </span><span># 轻量编码器：Embedding + 简单聚合</span><span>
│  ├─ aggregators.py       </span><span># WeightedSum / Attention 聚合</span><span>
│  └─ twin_tower.py        </span><span># 双塔主模型（相似度=余弦）</span><span>
│
├─ training/
│  ├─ __init__.py
│  ├─ train_loop.py        </span><span># 训练/验证循环</span><span>
│  ├─ evaluator.py         </span><span># 统一评估入口</span><span>
│  └─ splits.py            </span><span># 按“疾病”分层切分</span><span>
│
├─ scripts/
│  ├─ sanity_check.py      </span><span># 读少量TSV→跑一小批前向，验证“能跑通”</span><span>
│  ├─ run_train.py         </span><span># 主入口：加载配置→训练→保存模型</span><span>
│  └─ run_eval.py          </span><span># 载入模型→评估→输出指标</span><span>
│
└─ tests/
   ├─ test_schema_map.py
   ├─ test_joins.py
   ├─ test_filters.py
   ├─ test_aggregators.py
   └─ test_twin_tower.py
</span></span></code></div></div></pre>

---

# 每个代码文件要写什么（最小说明）

## config/

* **default.yaml**
  * 字段示例：`batch_size, epochs, lr, embedding_dim, temperature, topk_d, topk_f, topk_c, pki_threshold, seed`
  * 这些**都可留空或关闭**（例如 `topk_*: null` 表示不截断）。
* **paths.yaml**
  * 所需 TSV 的路径键（按列名文档）：
    * `D2_CPM`, `D4_CPM_CHP`, `D5_CPM_ICD11`, `D6_CHP`, `D9_CHP_InChIKey`, `D12_InChIKey`,
      `D19_ICD11_CUI`, `D20_ICD11_MeSH`, `D22_CUI_targets`, `D23_MeSH_targets`, `SD1_predicted`.
    * 各文件的列定义见 `schema_map.py`（依据《列名说明》原文）。

## dataio/

* **schema\_map.py**
  * 定义并注释每张表的**必需列**（保持原名）：
    * D4：`["CPM_ID","CHP_ID","Dosage_ratio"]`（中成药↔饮片）
    * D5：`["CPM_ID","ICD11_code"]`（中成药↔ICD11）
    * D6：`["CHP_ID","Chinese_herbal_pieces", ...]`（饮片主键）
    * D9：`["CHP_ID","InChIKey","Source"]`（饮片↔化合物）
    * D12：`["InChIKey","SMILES","MolWt","QED", ...]`（化合物理化特征）
    * D19：`["ICD11_code","CUI"]`；D20：`["ICD11_code","MeSH"]`
    * D22：`["CUI","EntrezID"]`；D23：`["MeSH","EntrezID"]`
    * SD1：`["InChIKey","EntrezID","predicted_binding_affinity"]`（预测亲和力）
  * 注释来源**逐条引用自《列名说明》**，不自造字段。
* **readers.py**
  * `read_tsv(name, path, required_cols)`：pandas 读入并校验必需列；空表/缺列直接抛错（报清楚哪个表缺哪列）。
* **joins.py**（**只做连接，不做业务过滤**）
  * `cpms_to_icd11(D5)` → CPM 与 ICD11 一对多映射。
  * `icd11_to_targets(D19,D20,D22,D23)` → ICD11 经 CUI/MeSH 汇总到 EntrezID 集合。
  * `cpms_to_chp(D4)` → CPM 到 CHP（保留 `Dosage_ratio`）。
  * `chp_to_chemicals(D9,D12)` → CHP 到化合物（并可拼上 D12 理化特征）。
  * `chemicals_to_targets(sd1_df)` → 化合物到 EntrezID（若存在实验表，可另写一个函数；默认用 SD1）。
  * `formulas_to_targets(...)` → `CPM→CHP→Chemical→Target` 聚合得到**方剂靶点集合**；返回结构如 `{formula_id: [target_ids], weights?}`。
  * `diseases_to_targets(...)` → `ICD11→(CUI/MeSH)→Target` 聚合得到**疾病靶点集合**。
  * 所有函数**仅返回内存 DataFrame/字典**。
* **filters.py**（全部**可选**，默认可不启用）
  * `filter_sd1_by_pki(sd1_df, threshold)`：按 `predicted_binding_affinity` 阈值过滤。
  * `per_chemical_topk(sd1_df, k)`：每化合物选前 k 个靶点。
  * `apply_topk_to_set(target_set, k)`：对疾病/方剂靶点集合截断。
  * `compute_inverse_freq(target_sets)`：返回靶点逆频权重向量。
  * `dosage_softmax(dosages, temperature)`：对 `Dosage_ratio` 做 softmax。
* **id\_maps.py**
  * 建立并冻结 5 类索引：`disease_idx, formula_idx, herb_idx, chemical_idx, target_idx`。
  * 保证同一 ID 每次运行得到同一索引（稳定复现）。
* **dataset\_builder.py**
  * 输入：疾病靶点集合、方剂靶点集合、以及 D5 的 (CPM, ICD11) 监督对。
  * 输出：训练所需的**正样本对**与用于采样的全集（负样在 batch 内或简单随机采）。

## core/

* **batching.py**
  * `Torch Dataset/DataLoader`：将集合型输入（若干 target\_id + 权重）打包为批，供模型聚合。
* **losses.py**
  * `info_nce(sim, temperature)`：对称 in-batch negatives。
* **metrics.py**
  * `recall_at_k`, `ndcg_at_k`。
* **utils.py**
  * 随机种设定、日志、断言（遇到空集合/索引越界立即报错）。

## models/

* **encoders.py**
  * `TargetEncoder`: `nn.Embedding(num_targets, d)`（**就用可学习Embedding**）。
  * `DiseaseEncoder`/`FormulaEncoder`: 取对应的 target\_id 列表 + 可选权重，调用 `aggregators` 得向量。
* **aggregators.py**
  * `WeightedSumAgg`（带权求和→L2 归一）；`AttentionAgg`（单头注意力）。
* **twin\_tower.py**
  * 组合两塔；输出余弦相似度矩阵与对比学习所需 logits。

## training/

* **train\_loop.py**
  * 标准训练循环（前向→loss→反传→日志）；周期性调 `evaluator`。
* **evaluator.py**
  * 给定划分，计算 Recall@K/NDCG@K。
* **splits.py**
  * 按“疾病”分层切分；留一部分“无分子信息疾病”用于冷启动评估（若存在）。口径来自你之前的阶段总结。

## scripts/

* **sanity\_check.py**
  * 只取每张表的前若干行：`readers→joins→dataset_builder→batching→模型前向`，打印一条相似度，**验证整链能跑通**。
* **run\_train.py**
  * 读 `config/*.yaml` → 完整流程（含可选过滤）→ 训练 → 保存 `model.pt` 与日志。
* **run\_eval.py**
  * 载入 `model.pt` → 评估 → 输出到控制台 + `results.json`。

## tests/

* 覆盖**纯函数**：
  * `test_schema_map.py`：逐表校验“必需列存在”。
  * `test_joins.py`：行数/键完整性（如 CPM 在 D5/D4 均能对齐）。
  * `test_filters.py`：TopK、softmax、逆频的数值正确性。
  * `test_aggregators.py`：聚合维度/归一化/可反传。
  * `test_twin_tower.py`：前向无 NaN，梯度存在。

---

## 约束与红线（避免再复杂化）

* **禁止**在训练/评估流程中写任何中间文件或做格式转换；**只读TSV、全在内存处理**。
* **可选**开关都放 `default.yaml`，默认可关；不要把任何阈值/TopK**硬编码**在函数里。
* 任一表**缺列或为空**立即 `raise ValueError`，并打印表名与缺失列名（定位问题第一时间）。
* **先跑通 `scripts/sanity_check.py`**，再运行 `run_train.py`。
