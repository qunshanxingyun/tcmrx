#!/usr/bin/env python3
"""
TCM-RX å®Œæ•´æ€§æ£€æŸ¥è„šæœ¬
è¯»å°‘é‡TSVâ†’è·‘ä¸€å°æ‰¹å‰å‘ï¼ŒéªŒè¯"èƒ½è·‘é€š"
"""

import sys
import os
from pathlib import Path
import logging
import time
import torch
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dataio.readers import TSVReader
from dataio.joins import *
from dataio.filters import *
from dataio.dataset_builder import TCMRXDataset
from models.twin_tower import DualTowerModel
from core.batching import create_data_loaders, collate_fn
from core.utils import load_config, get_device, setup_logging, set_random_seed
from training.splits import stratified_disease_split

logger = logging.getLogger(__name__)


def run_sanity_check(config_path: str = "config/default.yaml",
                     paths_path: str = "config/paths.yaml",
                     max_samples: int = 200,  # å¢åŠ æ ·æœ¬æ•°ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
                     max_cpms: int = 1000,    # å¢åŠ CPMæ•°é‡
                     max_diseases: int = 500):  # å¢åŠ ç–¾ç—…æ•°é‡
    """
    è¿è¡Œå®Œæ•´æ€§æ£€æŸ¥

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        paths_path: è·¯å¾„é…ç½®æ–‡ä»¶è·¯å¾„
        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        max_cpms: æœ€å¤§CPMæ•°é‡ï¼ˆå†…å­˜é™åˆ¶ï¼‰
        max_diseases: æœ€å¤§ç–¾ç—…æ•°é‡ï¼ˆå†…å­˜é™åˆ¶ï¼‰
    """
    # è®¾ç½®æ—¥å¿—
    setup_logging(level="INFO", experiment_name="sanity_check")
    logger.info("å¼€å§‹TCM-RXå®Œæ•´æ€§æ£€æŸ¥...")

    try:
        # 1. åŠ è½½é…ç½®
        logger.info("1. åŠ è½½é…ç½®...")
        config = load_config(config_path)
        paths_config = load_config(paths_path)

        # è®¾ç½®éšæœºç§å­
        set_random_seed(config['training']['seed'])

        # 2. è¯»å–æ•°æ®
        logger.info("2. è¯»å–æ•°æ®...")
        reader = TSVReader(paths_config)

        # è¯»å–å„è¡¨
        formula_tables = reader.read_formula_tables()
        disease_tables = reader.read_disease_tables()
        prediction_tables = reader.read_prediction_tables()

        logger.info(f"æˆåŠŸè¯»å–: æ–¹å‰‚è¡¨ {len(formula_tables)}, ç–¾ç—…è¡¨ {len(disease_tables)}, é¢„æµ‹è¡¨ {len(prediction_tables)}")

        # 3. æ•°æ®è¿æ¥
        logger.info("3. æ•°æ®è¿æ¥...")

        # æ–¹å‰‚ä¾§è¿æ¥
        cpms_to_chp_map = cpms_to_chp(formula_tables['D4_CPM_CHP'])
        d12_table = formula_tables.get('D12_InChIKey')
        chp_to_chemicals_map = chp_to_chemicals(formula_tables['D9_CHP_InChIKey'], d12_table)
        chemical_to_pathways_map = chemicals_to_pathways(d12_table)

        # é™åˆ¶chemical-to-targetsçš„æ•°æ®é‡ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
        sd1_df = prediction_tables['SD1_predicted']
        max_chemical_rows = min(100000, len(sd1_df))  # æœ€å¤š10ä¸‡è¡Œé¢„æµ‹æ•°æ®
        if len(sd1_df) > max_chemical_rows:
            logger.info(f"é™åˆ¶åŒ–å­¦-é¶ç‚¹é¢„æµ‹æ•°æ®ï¼š{len(sd1_df)} -> {max_chemical_rows} è¡Œ")
            sd1_df = sd1_df.sample(n=max_chemical_rows, random_state=42)

        chemical_to_targets_map = chemicals_to_targets(
            sd1_df,
            prediction_tables.get('D13_InChIKey_EntrezID')
        )

        pathway_config = config.get('pathways', {})
        target_to_pathways_map = build_target_to_pathways(
            chemical_to_targets_map,
            chemical_to_pathways_map,
            prefix=pathway_config.get('prefix', 'pathway:'),
            max_pathways_per_target=pathway_config.get('bridge', {}).get('max_pathways_per_target', 32),
            min_weight=pathway_config.get('bridge', {}).get('min_weight', 1e-4),
        )

        # ç–¾ç—…ä¾§è¿æ¥
        icd11_to_targets_map = icd11_to_targets(
            disease_tables['D19_ICD11_CUI'],
            disease_tables['D20_ICD11_MeSH'],
            disease_tables['D22_CUI_targets'],
            disease_tables['D23_MeSH_targets']
        )

        # æ„å»ºæ–¹å‰‚é¶ç‚¹é›†åˆ
        logger.info("æ„å»ºæ–¹å‰‚é¶ç‚¹é›†åˆ...")
        formula_targets_raw = formulas_to_targets(
            cpms_to_chp_map,
            chp_to_chemicals_map,
            chemical_to_targets_map,
            chemical_to_pathways_map=chemical_to_pathways_map,
            pathway_config=pathway_config,
        )

        # æ„å»ºç–¾ç—…é¶ç‚¹é›†åˆ
        logger.info("æ„å»ºç–¾ç—…é¶ç‚¹é›†åˆ...")
        disease_targets_raw = diseases_to_targets(
            icd11_to_targets_map,
            target_to_pathways_map=target_to_pathways_map,
            pathway_config=pathway_config,
        )

        # è·å–ç›‘ç£å¯¹
        cpms_to_icd11_map = cpms_to_icd11(formula_tables['D5_CPM_ICD11'])
        positive_pairs_raw = [(icd11, cpm) for cpm, icd11_list in cpms_to_icd11_map.items() for icd11 in icd11_list]

        logger.info(f"è¿æ¥å®Œæˆ: {len(formula_targets_raw)} æ–¹å‰‚, {len(disease_targets_raw)} ç–¾ç—…, {len(positive_pairs_raw)} æ­£æ ·æœ¬å¯¹")

        # å…ˆå¯¹ç›‘ç£å¯¹è¿›è¡Œé‡‡æ ·ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        if max_samples and len(positive_pairs_raw) > max_samples:
            logger.info(f"é™åˆ¶ç›‘ç£å¯¹æ•°é‡: {len(positive_pairs_raw)} -> {max_samples}")
            import random
            random.seed(config['training']['seed'])
            positive_pairs_raw = random.sample(positive_pairs_raw, max_samples)

        # æ ¹æ®é‡‡æ ·çš„ç›‘ç£å¯¹ç¡®å®šéœ€è¦ä¿ç•™çš„CPMå’Œç–¾ç—…
        sampled_cpms = set(cpm for _, cpm in positive_pairs_raw)
        sampled_diseases = set(icd11 for icd11, _ in positive_pairs_raw)

        # è¿‡æ»¤æ•°æ®ä»¥åŒ¹é…é‡‡æ ·çš„ç›‘ç£å¯¹
        logger.info(f"æ ¹æ®ç›‘ç£å¯¹è¿‡æ»¤æ•°æ®: CPM {len(cpms_to_chp_map)} -> {len(sampled_cpms)}")
        cpms_to_chp_map = {cpm: data for cpm, data in cpms_to_chp_map.items() if cpm in sampled_cpms}

        logger.info(f"æ ¹æ®ç›‘ç£å¯¹è¿‡æ»¤æ•°æ®: ç–¾ç—… {len(icd11_to_targets_map)} -> {len(sampled_diseases)}")
        icd11_to_targets_map = {icd11: data for icd11, data in icd11_to_targets_map.items() if icd11 in sampled_diseases}

        # 4. è¿‡æ»¤å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        logger.info("4. åº”ç”¨è¿‡æ»¤...")
        filtering_config = config.get('filtering', {})

        # SD1è¿‡æ»¤ï¼ˆä½¿ç”¨å·²é‡‡æ ·çš„sd1_dfï¼‰
        if filtering_config.get('pki_threshold'):
            sd1_df = filter_sd1_by_pki(sd1_df, filtering_config['pki_threshold'])
            # é‡æ–°æ„å»ºåŒ–å­¦-é¶ç‚¹æ˜ å°„
            chemical_to_targets_map = chemicals_to_targets(
                sd1_df,
                prediction_tables.get('D13_InChIKey_EntrezID')
            )
            target_to_pathways_map = build_target_to_pathways(
                chemical_to_targets_map,
                chemical_to_pathways_map,
                prefix=pathway_config.get('prefix', 'pathway:'),
                max_pathways_per_target=pathway_config.get('bridge', {}).get('max_pathways_per_target', 32),
                min_weight=pathway_config.get('bridge', {}).get('min_weight', 1e-4),
            )
            formula_targets_raw = formulas_to_targets(
                cpms_to_chp_map,
                chp_to_chemicals_map,
                chemical_to_targets_map,
                chemical_to_pathways_map=chemical_to_pathways_map,
                pathway_config=pathway_config,
            )
            disease_targets_raw = diseases_to_targets(
                icd11_to_targets_map,
                target_to_pathways_map=target_to_pathways_map,
                pathway_config=pathway_config,
            )

        # 6. æ„å»ºæ•°æ®é›†
        logger.info("6. æ„å»ºæ•°æ®é›†...")
        logger.info(f"è¾“å…¥æ•°æ®ç»Ÿè®¡: æ–¹å‰‚é¶ç‚¹ {len(formula_targets_raw)}, ç–¾ç—…é¶ç‚¹ {len(disease_targets_raw)}, ç›‘ç£å¯¹ {len(positive_pairs_raw)}")

        dataset = TCMRXDataset(config)
        dataset.build_from_raw_data(disease_targets_raw, formula_targets_raw, positive_pairs_raw, split_name='train')

        logger.info(f"æ•°æ®é›†æ„å»ºå®Œæˆ: {dataset}")
        logger.info(f"è®­ç»ƒæ ·æœ¬æ•°é‡: {len(dataset.training_samples) if hasattr(dataset, 'training_samples') else 'æœªçŸ¥'}")

        # 7. åˆ›å»ºæ¨¡å‹
        logger.info("7. åˆ›å»ºæ¨¡å‹...")
        device = get_device(config['training']['device'])

        # è®¾ç½®å®ä½“æ•°é‡
        disease_indices, formula_indices, num_targets = dataset.get_entity_indices()
        model_config = {
            'embedding_dim': config['model']['embedding_dim'],
            'dropout_rate': config['model']['dropout_rate'],
            'temperature': config['model']['temperature'],
            'aggregator_type': config['model']['aggregator_type']
        }
        model = DualTowerModel(model_config)
        model.set_entity_counts(len(disease_indices), len(formula_indices), num_targets)
        model = model.to(device)

        logger.info(f"æ¨¡å‹åˆ›å»ºå®Œæˆ: å‚æ•°é‡ {sum(p.numel() for p in model.parameters()):,}")

        # 8. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        logger.info("8. åˆ›å»ºæ•°æ®åŠ è½½å™¨...")

        # ç®€å•åˆ’åˆ†ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
        split_ratio = 0.8
        split_idx = int(len(dataset) * split_ratio)
        train_samples = dataset.training_samples[:split_idx]
        val_samples = dataset.training_samples[split_idx:]

        # ä¸´æ—¶ä¿®æ”¹æ•°æ®é›†çš„è®­ç»ƒæ ·æœ¬
        dataset.training_samples = train_samples

        train_loader, _ = create_data_loaders(
            dataset, None,
            batch_size=min(config['training']['batch_size'], 16),  # å°æ‰¹æ¬¡
            num_workers=0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )

        logger.info(f"æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ: è®­ç»ƒé›† {len(train_loader.dataset)} æ ·æœ¬")

        # 9. å‰å‘ä¼ æ’­æµ‹è¯•
        logger.info("9. å‰å‘ä¼ æ’­æµ‹è¯•...")
        model.eval()

        with torch.no_grad():
            for batch_idx, batch in enumerate(train_loader):
                # ç§»åŠ¨åˆ°è®¾å¤‡
                batch = {k: v.to(device) for k, v in batch.items()}

                # å‰å‘ä¼ æ’­
                outputs = model(batch)

                # æ£€æŸ¥è¾“å‡º
                similarities = outputs['similarities']
                logger.info(f"æ‰¹æ¬¡ {batch_idx + 1}: ç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶ {similarities.shape}")
                logger.info(f"æ‰¹æ¬¡ {batch_idx + 1}: ç›¸ä¼¼åº¦èŒƒå›´ [{similarities.min().item():.4f}, {similarities.max().item():.4f}]")

                # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
                break

        # 10. æˆåŠŸéªŒè¯
        logger.info("=" * 60)
        logger.info("ğŸ‰ TCM-RXå®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ï¼")
        logger.info("æ‰€æœ‰æ ¸å¿ƒç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œ:")
        logger.info("  âœ… æ•°æ®è¯»å–å’Œè¿æ¥")
        logger.info("  âœ… æ•°æ®é›†æ„å»º")
        logger.info("  âœ… æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­")
        logger.info("  âœ… æ‰¹å¤„ç†æµæ°´çº¿")
        logger.info("=" * 60)

        return True

    except Exception as e:
        logger.error("=" * 60)
        logger.error("âŒ å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥!")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        logger.error("=" * 60)
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_sanity_check()
    sys.exit(0 if success else 1)