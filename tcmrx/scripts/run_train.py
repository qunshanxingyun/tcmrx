#!/usr/bin/env python3
"""
TCM-RX ä¸»è®­ç»ƒè„šæœ¬
è¯»é…ç½®â†’è®­ç»ƒâ†’ä¿å­˜æ¨¡å‹
"""

import sys
import os
from pathlib import Path
import logging
import time
import argparse
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dataio.readers import TSVReader
from dataio.joins import *
from dataio.filters import *
from dataio.dataset_builder import TCMRXDataset
from models.twin_tower import DualTowerModel
from core.batching import create_data_loaders
from core.utils import load_config, get_device, setup_logging, set_random_seed, log_model_info
from core.losses import InfoNCELoss
from training.train_loop import TrainingLoop
from training.splits import stratified_disease_split, identify_cold_start_diseases, validate_split, create_cold_start_split
from training.evaluator import ModelEvaluator

logger = logging.getLogger(__name__)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="TCM-RX è®­ç»ƒè„šæœ¬")

    parser.add_argument("--config", type=str, default="config/default.yaml",
                        help="æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--paths", type=str, default="config/paths.yaml",
                        help="æ•°æ®è·¯å¾„é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--experiment", type=str, default=None,
                        help="å®éªŒåç§°ï¼ˆè‡ªåŠ¨ç”Ÿæˆå¦‚æœä¸ºç©ºï¼‰")
    parser.add_argument("--resume", type=str, default=None,
                        help="æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„")
    parser.add_argument("--seed", type=int, default=None,
                        help="éšæœºç§å­ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--device", type=str, default=None,
                        choices=["auto", "cpu", "cuda"],
                        help="è®¡ç®—è®¾å¤‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--epochs", type=int, default=None,
                        help="è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--batch-size", type=int, default=None,
                        help="æ‰¹å¤§å°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰")
    parser.add_argument("--lr", type=float, default=None,
                        help="å­¦ä¹ ç‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰")

    return parser.parse_args()


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    args = parse_arguments()

    # åŠ è½½é…ç½®
    config = load_config(args.config)
    paths_config = load_config(args.paths)

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if args.seed is not None:
        config['training']['seed'] = args.seed
    if args.device is not None:
        config['training']['device'] = args.device
    if args.epochs is not None:
        config['training']['epochs'] = args.epochs
    if args.batch_size is not None:
        config['training']['batch_size'] = args.batch_size
    if args.lr is not None:
        config['training']['lr'] = args.lr

    # è®¾ç½®å®éªŒåç§°
    if args.experiment is None:
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        args.experiment = f"tcmrx_train_{timestamp}"

    # è®¾ç½®æ—¥å¿—
    setup_logging(
        log_dir=config['logging']['log_dir'],
        level="INFO",
        experiment_name=args.experiment
    )

    logger.info("å¼€å§‹TCM-RXè®­ç»ƒ")
    logger.info(f"å®éªŒåç§°: {args.experiment}")
    logger.info(f"é…ç½®æ–‡ä»¶: {args.config}")
    logger.info(f"è·¯å¾„é…ç½®: {args.paths}")

    start_time = time.time()

    try:
        # 1. è®¾ç½®éšæœºç§å­å’Œè®¾å¤‡
        set_random_seed(config['training']['seed'])
        device = get_device(config['training']['device'])
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

        # 2. è¯»å–æ•°æ®
        logger.info("è¯»å–æ•°æ®...")
        reader = TSVReader(paths_config)

        formula_tables = reader.read_formula_tables()
        disease_tables = reader.read_disease_tables()
        prediction_tables = reader.read_prediction_tables()

        logger.info(f"æ•°æ®è¯»å–å®Œæˆ: {len(formula_tables)} æ–¹å‰‚è¡¨, {len(disease_tables)} ç–¾ç—…è¡¨, {len(prediction_tables)} é¢„æµ‹è¡¨")

        # 3. æ•°æ®è¿æ¥å’Œè¿‡æ»¤
        logger.info("æ•°æ®è¿æ¥å’Œè¿‡æ»¤...")
        filtering_config = config.get('filtering', {})

        # æ–¹å‰‚ä¾§è¿æ¥
        cpms_to_chp_map = cpms_to_chp(formula_tables['D4_CPM_CHP'])
        chp_to_chemicals_map = chp_to_chemicals(formula_tables['D9_CHP_InChIKey'], formula_tables.get('D12_InChIKey'))

        # å¤„ç†åŒ–å­¦-é¶ç‚¹é¢„æµ‹
        sd1_df = prediction_tables['SD1_predicted']
        sd1_df = filter_sd1_by_pki(sd1_df, filtering_config.get('pki_threshold'))
        chemical_to_targets_map = per_chemical_topk(
            chemicals_to_targets(sd1_df), filtering_config.get('topk_c')
        )

        # ç–¾ç—…ä¾§è¿æ¥
        icd11_to_targets_map = icd11_to_targets(
            disease_tables['D19_ICD11_CUI'],
            disease_tables['D20_ICD11_MeSH'],
            disease_tables['D22_CUI_targets'],
            disease_tables['D23_MeSH_targets']
        )

        # æ„å»ºé¶ç‚¹é›†åˆ
        formula_targets_raw = formulas_to_targets(cpms_to_chp_map, chp_to_chemicals_map, chemical_to_targets_map)
        disease_targets_raw = diseases_to_targets(icd11_to_targets_map)

        # è·å–ç›‘ç£å¯¹
        cpms_to_icd11_map = cpms_to_icd11(formula_tables['D5_CPM_ICD11'])
        positive_pairs_raw = [(icd11, cpm) for cpm, icd11_list in cpms_to_icd11_map.items() for icd11 in icd11_list]

        logger.info(f"æ•°æ®å¤„ç†å®Œæˆ: {len(formula_targets_raw)} æ–¹å‰‚, {len(disease_targets_raw)} ç–¾ç—…, {len(positive_pairs_raw)} æ­£æ ·æœ¬å¯¹")

        # 4. æ•°æ®åˆ’åˆ†
        logger.info("æ•°æ®åˆ’åˆ†...")
        split_config = config['split']
        split_result = stratified_disease_split(
            positive_pairs_raw,
            train_ratio=split_config['train_ratio'],
            val_ratio=split_config['val_ratio'],
            test_ratio=split_config['test_ratio'],
            seed=config['training']['seed']
        )

        # éªŒè¯åˆ’åˆ†
        if not validate_split(split_result):
            raise ValueError("æ•°æ®åˆ’åˆ†éªŒè¯å¤±è´¥")

        # å†·å¯åŠ¨è¯†åˆ«ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        cold_start_splits = {}
        if split_config.get('cold_start_eval'):
            diseases_with_targets, cold_start_diseases = identify_cold_start_diseases(
                positive_pairs_raw, disease_targets_raw
            )
            if cold_start_diseases:
                cold_start_splits = create_cold_start_split(
                    positive_pairs_raw, cold_start_diseases,
                    train_ratio=split_config['train_ratio'],
                    val_ratio=split_config['val_ratio'],
                    test_ratio=split_config['test_ratio'],
                    seed=config['training']['seed']
                )

        # 5. æ„å»ºæ•°æ®é›†
        logger.info("æ„å»ºæ•°æ®é›†...")
        dataset = TCMRXDataset(config)
        dataset.build_from_raw_data(disease_targets_raw, formula_targets_raw, split_result['train'])

        logger.info(f"è®­ç»ƒæ•°æ®é›†: {dataset}")

        # 6. åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºæ¨¡å‹...")
        model_config = config['model']
        model = DualTowerModel(model_config)

        # è®¾ç½®å®ä½“æ•°é‡
        disease_indices, formula_indices, num_targets = dataset.get_entity_indices()
        model.set_entity_counts(len(disease_indices), len(formula_indices), num_targets)
        model = model.to(device)

        log_model_info(model)

        # 7. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        logger.info("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")

        # æ„å»ºéªŒè¯æ•°æ®é›†
        if split_result['val']:
            val_dataset = TCMRXDataset(config)
            val_dataset.build_from_raw_data(disease_targets_raw, formula_targets_raw, split_result['val'])
        else:
            val_dataset = None

        train_loader, val_loader = create_data_loaders(
            dataset, val_dataset,
            batch_size=config['training']['batch_size'],
            num_workers=config['training'].get('num_workers', 4),
            pin_memory=True
        )

        # 8. åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        logger.info("åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°...")
        optimizer = torch.optim.Adam(
            model.parameters(),
            lr=config['training']['lr'],
            weight_decay=config['training']['weight_decay']
        )

        loss_fn = InfoNCELoss(temperature=model.get_temperature())

        # 9. åˆ›å»ºè®­ç»ƒå¾ªç¯
        logger.info("å¼€å§‹è®­ç»ƒ...")
        training_loop = TrainingLoop(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader,
            optimizer=optimizer,
            device=device,
            mixed_precision=config['training']['mixed_precision']
        )

        # 10. æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.resume:
            logger.info(f"æ¢å¤è®­ç»ƒ: {args.resume}")
            from core.utils import load_checkpoint
            checkpoint = load_checkpoint(args.resume, device)
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            training_loop.current_epoch = checkpoint['epoch']

        # 11. å¼€å§‹è®­ç»ƒ
        training_loop.train(
            num_epochs=config['training']['epochs'],
            save_every=config['training']['eval_every'],
            validate_every=config['training']['eval_every'],
            checkpoint_dir=config['logging']['checkpoint_dir'],
            experiment_name=args.experiment
        )

        # 12. æœ€ç»ˆè¯„ä¼°
        logger.info("æœ€ç»ˆè¯„ä¼°...")
        if val_loader:
            evaluator = ModelEvaluator(model, device)
            final_metrics = evaluator.evaluate_dataset(val_loader)

            # ä¿å­˜è¯„ä¼°ç»“æœ
            evaluator.save_evaluation_results(
                final_metrics,
                f"{config['logging']['checkpoint_dir']}/{args.experiment}_final_metrics.json"
            )

            logger.info("æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡:")
            for k, v in final_metrics.items():
                if any(metric in k for metric in ['recall', 'precision', 'ndcg', 'mrr']):
                    logger.info(f"  {k}: {v:.4f}")

        total_time = time.time() - start_time
        logger.info("=" * 60)
        logger.info("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        logger.info(f"æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
        logger.info(f"å®éªŒåç§°: {args.experiment}")
        logger.info("=" * 60)

    except Exception as e:
        logger.error("=" * 60)
        logger.error("âŒ è®­ç»ƒå¤±è´¥!")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        logger.error("=" * 60)
        sys.exit(1)


if __name__ == "__main__":
    main()